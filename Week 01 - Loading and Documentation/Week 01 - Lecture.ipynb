{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8196d1",
   "metadata": {},
   "source": [
    "# INFO 3402 â€“ Week 01: Lecture\n",
    "\n",
    "[Brian C. Keegan, Ph.D.](http://brianckeegan.com/)  \n",
    "[Assistant Professor, Department of Information Science](https://www.colorado.edu/cmci/people/information-science/brian-c-keegan)  \n",
    "University of Colorado Boulder  \n",
    "\n",
    "Copyright and distributed under an [MIT License](https://opensource.org/licenses/MIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3054c",
   "metadata": {},
   "source": [
    "## Does this notebook work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b348e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} has the best haircut of any INFO faculty!\".format('Brian Keegan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec91168",
   "metadata": {},
   "source": [
    "## Can you load libraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed visualization outputs in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import matplotlib's pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Customize pandas to display more columns than default\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723df9cc",
   "metadata": {},
   "source": [
    "## Can you load data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859374e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://data.census.gov/cedsci/table?q=DP05&g=0100000US%240400000&tid=ACSDP1Y2019.DP05&moe=false&tp=true\n",
    "census_df = pd.read_csv('ACS2019_DP05_state.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c38ad",
   "metadata": {},
   "source": [
    "## What does this data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a317ba",
   "metadata": {},
   "source": [
    "From the Census documentation:\n",
    "\n",
    "<ol><li>An \"**\" entry in the margin of error column indicates that either no sample observations or too few sample observations were available to compute a standard error and thus the margin of error. A statistical test is not appropriate.</li><li>An \"-\" entry in the estimate column indicates that either no sample observations or too few sample observations were available to compute an estimate, or a ratio of medians cannot be calculated because one or both of the median estimates falls in the lowest interval or upper interval of an open-ended distribution, or the margin of error associated with a median was larger than the median itself.</li><li>An \"-\" following a median estimate means the median falls in the lowest interval of an open-ended distribution.</li><li>An \"+\" following a median estimate means the median falls in the upper interval of an open-ended distribution.</li><li>An \"***\" entry in the margin of error column indicates that the median falls in the lowest interval or upper interval of an open-ended distribution. A statistical test is not appropriate.</li><li>An \"*****\" entry in the margin of error column indicates that the estimate is controlled. A statistical test for sampling variability is not appropriate. </li><li>An \"N\" entry in the estimate and margin of error columns indicates that data for this geographic area cannot be displayed because the number of sample cases is too small.</li><li>An \"(X)\" means that the estimate is not applicable or not available.</li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d8cce",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Pandas's `read_csv` function has a lot of powerful functionality built into it. Check out the [User Guide for CSV files](https://pandas.pydata.org/docs/user_guide/io.html#csv-text-files) or the reference for the [`read_csv` function](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n",
    "\n",
    "### Exercise 1: Fix the problem with column names being the 0th row of data\n",
    "\n",
    "We don't need the column names like \"DP05_001E\" since they're hard-to-understand. The second row of columns names like \"Estimate!!SEX AND AGE!!Total population\" are more useful, but were read in as a row of data. \n",
    "\n",
    "Use the `read_csv` function to make the helpful names on the second row the column names for the DataFrame and assign to `dp05_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c2af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b610bce",
   "metadata": {},
   "source": [
    "### Exercise 2: Fix the multiple kinds of NaN values\n",
    "\n",
    "There are multiple kinds of missing data (see the Census documentation above). It's often helpful to know *why* the data is missing, but for our purposes we only care if the data is present or absent.\n",
    "\n",
    "Use the `read_csv` function to convert these different types of missing data values into a consistent `NaN`  and assign to `dp05_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db167c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604948b0",
   "metadata": {},
   "source": [
    "### Exercise 3: Online include column names containing \"Estimate\"\n",
    "\n",
    "The American Community Survey (ACS) is a sample of the population rather than the full census. So the esimates reported have some sampling error in them. Each column is actually part of a triplet: (estimate, margin of error, and percent). We only care about the columns with the name \"Estimate\" in them for this exercise.\n",
    "\n",
    "Use the `read_csv` function to filter the columns down to only those that contain the string \"Estimate\" and assign to `dp05_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf72ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b1b49d6",
   "metadata": {},
   "source": [
    "### Exercise 4: Sort by Asian population\n",
    "Sort the `dp05_df` DataFrame by the \"Estimate!!RACE!!Total population!!One race!!Asian\" column. What states have the largest Asian population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b76c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d29536",
   "metadata": {},
   "source": [
    "### Exercise 5: Compute and sort on a new column\n",
    "States with a large Asian population may simply have large populations. We lost the percentages in Exercise 3. Let's compute the percentage of the population that is Asian. Divide the column used in Exercise 4 by the Total Population estimate and store as \"Asian percentage\". Sort on \"Asian percentage\" show the top 5 and bottom 5 states by Asian population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91342aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
